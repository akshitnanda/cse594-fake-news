{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning messages\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Computations\n",
    "import itertools\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Input Data from CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training, test and validation files\n",
    "train=pd.read_csv('./liar_plus_dataset/dataset/tsv/train2.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "test=pd.read_csv('./liar_plus_dataset/dataset/tsv/test2.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "valid=pd.read_csv('./liar_plus_dataset/dataset/tsv/val2.tsv',delimiter='\\t',encoding='utf-8', header=None)\n",
    "\n",
    "# Create table headers    \n",
    "train.columns = ['values','id','label','statement','subject','speaker', 'job', 'state','party','barely_true_c','false_c','half_true_c','mostly_true_c','pants_on_fire_c','venue','extracted_justification']\n",
    "test.columns = ['values','id','label','statement','subject','speaker', 'job', 'state','party','barely_true_c','false_c','half_true_c','mostly_true_c','pants_on_fire_c','venue','extracted_justification']\n",
    "valid.columns = ['values','id','label','statement','subject','speaker', 'job', 'state','party','barely_true_c','false_c','half_true_c','mostly_true_c','pants_on_fire_c','venue','extracted_justification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending Train and Validation Sets to Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = train.append(valid).sample(frac = 1, random_state = 1)\n",
    "df.index = range(len(train) + len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'Statement' + 'Justification' Columns for Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total'] = df['statement'] + ' ' + df['extracted_justification'] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['total'] = test['statement'] + ' ' + test['extracted_justification']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df['label'].unique()\n",
    "# df[df['label'].isna()]\n",
    "df = df.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['label'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Classification Labels for Binary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "truth_ = {'pants-fire':1, 'false':1, 'barely-true':1, 'half-true':0, 'mostly-true':0, 'true':0}\n",
    "df['lblClass'] = df['label'].apply(lambda x: truth_[x])\n",
    "test['lblClass'] = test['label'].apply(lambda x: truth_[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.isnull().sum()\n",
    "# test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test 80-20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['total']\n",
    "y_train = df['lblClass']\n",
    "X_test = test['total']\n",
    "y_test = test['lblClass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n",
    "# Fit and transform the training data.\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "#Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "#Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Confusion Matrix Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that outputs a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(true_label, predicted_label):\n",
    "    precision = precision_score(true_label, predicted_label)\n",
    "    print('Precision: %f' % precision)\n",
    "\n",
    "    recall = recall_score(true_label, predicted_label)\n",
    "    print('Recall: %f' % recall)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(true_label, predicted_label)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    \n",
    "    f1score = metrics.f1_score(true_label, predicted_label)\n",
    "    print('F1 Score: %f' % f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_classifier_k = MultinomialNB(alpha=0.1)\n",
    "scores = cross_val_score(nb_classifier_k, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier_k.fit(count_train, y_train)\n",
    "pred_nb_c = nb_classifier_k.predict(count_test)\n",
    "precision_recall(y_test, pred_nb_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tune the hyperparameter alpha for the MultinomialNB classifier\n",
    "for alpha in np.arange(0,1,.05):\n",
    "    nb_classifier_tune = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier_tune.fit(count_train, y_train)\n",
    "    pred_tune = nb_classifier_tune.predict(count_test)\n",
    "    precision_recall(y_test, pred_tune)\n",
    "    print(\"Alpha: {:.2f} \".format(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running our fine-tuned model and plotting the results\n",
    "nb_classifier = MultinomialNB(alpha = 0.30)\n",
    "scores = cross_val_score(nb_classifier, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred_nb_count = nb_classifier.predict(count_test)\n",
    "precision_recall(y_test, pred_nb_count)\n",
    "cm = metrics.confusion_matrix(y_test, pred_nb_count, labels=[0,1])\n",
    "    \n",
    "    \n",
    "plot_confusion_matrix(cm, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_classifier_k = MultinomialNB(alpha=0.1)\n",
    "scores = cross_val_score(nb_classifier_k, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier_k.fit(tfidf_train, y_train)\n",
    "pred_nb_c = nb_classifier_k.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_nb_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tune the hyperparameter alpha for the MultinomialNB classifier\n",
    "for alpha in np.arange(0,1,.05):\n",
    "    nb_classifier_tune = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier_tune.fit(tfidf_train, y_train)\n",
    "    pred_tune = nb_classifier_tune.predict(tfidf_test)\n",
    "    precision_recall(y_test, pred_tune)\n",
    "    print(\"Alpha: {:.2f} \".format(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running our fine-tuned model and plotting the results\n",
    "nb_classifier = MultinomialNB(alpha = 0.30)\n",
    "scores = cross_val_score(nb_classifier, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred_nb_count = nb_classifier.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_nb_count)\n",
    "cm = metrics.confusion_matrix(y_test, pred_nb_count, labels=[0,1])\n",
    "    \n",
    "    \n",
    "plot_confusion_matrix(cm, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Tf-IDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "scores = cross_val_score(logreg, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "logreg.fit(count_train, y_train)\n",
    "pred_logreg_count = logreg.predict(count_test)\n",
    "pred_logreg_count_proba = logreg.predict_proba(count_test)[:,1]\n",
    "precision_recall(y_test, pred_logreg_count)\n",
    "\n",
    "cm4 = metrics.confusion_matrix(y_test, pred_logreg_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "scores = cross_val_score(logreg, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "logreg.fit(tfidf_train, y_train)\n",
    "pred_logreg_tfidf = logreg.predict(tfidf_test)\n",
    "pred_logreg_tfidf_proba = logreg.predict_proba(tfidf_test)[:,1]\n",
    "precision_recall(y_test, pred_logreg_tfidf)\n",
    "\n",
    "cm4 = metrics.confusion_matrix(y_test, pred_logreg_tfidf, labels=[0,1])\n",
    "plot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Tf-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclass = SVC(kernel = 'linear', random_state = 0)\n",
    "scores = cross_val_score(svclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "svclass.fit(count_train, y_train)\n",
    "pred_sv_count = svclass.predict(count_test)\n",
    "precision_recall(y_test, pred_sv_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_sv_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a LSVM with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclass = SVC(kernel = 'linear', random_state = 0)\n",
    "scores = cross_val_score(svclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "svclass.fit(tfidf_train, y_train)\n",
    "pred_sv_tfidf = svclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_sv_tfidf)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_sv_tfidf, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a LSVM with TFIDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclass = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(dtclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "dtclass.fit(count_train, y_train)\n",
    "pred_dt_count = dtclass.predict(count_test)\n",
    "precision_recall(y_test, pred_dt_count)\n",
    "\n",
    "cm5 = metrics.confusion_matrix(y_test, pred_dt_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a DT with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclass = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(dtclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "dtclass.fit(tfidf_train, y_train)\n",
    "pred_dt_tfidf = dtclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_dt_tfidf)\n",
    "\n",
    "cm5 = metrics.confusion_matrix(y_test, pred_dt_tfidf, labels=[0,1])\n",
    "plot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a DT with TFIDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfclass = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(rfclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "rfclass.fit(count_train, y_train)\n",
    "pred_rf_count = rfclass.predict(count_test)\n",
    "precision_recall(y_test, pred_rf_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_rf_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a RF with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfclass = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(rfclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "rfclass.fit(tfidf_train, y_train)\n",
    "pred_rf_tfidf = rfclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_rf_tfidf)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_rf_idf, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a RF with TFIDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "scores = cross_val_score(knnclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "knnclass.fit(count_train, y_train)\n",
    "pred_knn_count = knnclass.predict(count_test)\n",
    "precision_recall(y_test, pred_knn_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_knn_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a KNN with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "scores = cross_val_score(knnclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "knnclass.fit(tfidf_train, y_train)\n",
    "pred_knn_tfidf = knnclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_knn_tfidf)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_knn_tfidf, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a KNN with TFIDF Vectorizer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
