{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning messages\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Handle table-like data and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Computations\n",
    "import itertools\n",
    "\n",
    "# Modelling Algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Fake and Real Data from CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('./bin_dataset/Fake.csv', delimiter = ',')\n",
    "true = pd.read_csv('./bin_dataset/True.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the 'Reuters' Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_prefix(text,prefix='(Reuters)',n=5):\n",
    "    ts = str.split(text,' ')\n",
    "    if prefix in ts[:n]:\n",
    "        return str.split(text,prefix)[-1]\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning 0 and 1 labels to Fake and Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake['label']= 0\n",
    "true['label']= 1\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "dataset = true.append(fake).sample(frac = 1, random_state = 1)\n",
    "dataset.index = range(len(true) + len(fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.shape[0]):\n",
    "    dataset['text'][i] =  drop_prefix(dataset['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Dataset Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for NULL values in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the text and title fields for \"full text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['total'] = dataset['title'] + dataset['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test 80-20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset['total'], dataset.label, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n",
    "# Fit and transform the training data.\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "#Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "#Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Confusion Matrix Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that outputs a confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(true_label, predicted_label):\n",
    "    precision = precision_score(true_label, predicted_label)\n",
    "    print('Precision: %f' % precision)\n",
    "\n",
    "    recall = recall_score(true_label, predicted_label)\n",
    "    print('Recall: %f' % recall)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(true_label, predicted_label)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    \n",
    "    f1score = metrics.f1_score(true_label, predicted_label)\n",
    "    print('F1 Score: %f' % f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_k = MultinomialNB(alpha=0.1)\n",
    "scores = cross_val_score(nb_classifier_k, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier_k.fit(count_train, y_train)\n",
    "pred_nb_c = nb_classifier_k.predict(count_test)\n",
    "precision_recall(y_test, pred_nb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tune the hyperparameter alpha for the MultinomialNB classifier\n",
    "for alpha in np.arange(0,1,.05):\n",
    "    nb_classifier_tune = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier_tune.fit(count_train, y_train)\n",
    "    pred_tune = nb_classifier_tune.predict(count_test)\n",
    "    precision_recall(y_test, pred_tune)\n",
    "    print(\"Alpha: {:.2f} \".format(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Running our fine-tuned model with alpha=0.05 and plotting the results\n",
    "nb_classifier = MultinomialNB(alpha = 0.05)\n",
    "scores = cross_val_score(nb_classifier_k, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred_nb_count = nb_classifier.predict(count_test)\n",
    "precision_recall(y_test, pred_nb_count)\n",
    "cm = metrics.confusion_matrix(y_test, pred_nb_count, labels=[0,1])\n",
    "    \n",
    "    \n",
    "plot_confusion_matrix(cm, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB(alpha = 0.1)\n",
    "scores = cross_val_score(nb_classifier_k, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred_nb_tfidf = nb_classifier.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_nb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tune the hyperparameter alpha for the MultinomialNB classifier\n",
    "for alpha in np.arange(0,0.1,.01):\n",
    "    nb_classifier_tune = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier_tune.fit(tfidf_train, y_train)\n",
    "    pred_tune = nb_classifier_tune.predict(tfidf_test)\n",
    "    precision_recall(y_test, pred_tune)\n",
    "    print(\"Alpha: {:.2f} \".format(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running our fine-tuned model with alpha=0.05 and plotting the results\n",
    "nb_classifier = MultinomialNB(alpha = 0.05)\n",
    "scores = cross_val_score(nb_classifier_k, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred_nb_tfidf = nb_classifier.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_nb_tfidf)\n",
    "cm2 = metrics.confusion_matrix(y_test, pred_nb_tfidf, labels=[0,1])\n",
    "plot_confusion_matrix(cm2, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Tf-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "scores = cross_val_score(logreg, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "logreg.fit(count_train, y_train)\n",
    "pred_logreg_count = logreg.predict(count_test)\n",
    "precision_recall(y_test, pred_logreg_count)\n",
    "\n",
    "cm3 = metrics.confusion_matrix(y_test, pred_logreg_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm3, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "scores = cross_val_score(logreg, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "logreg.fit(tfidf_train, y_train)\n",
    "pred_logreg_tfidf = logreg.predict(tfidf_test)\n",
    "pred_logreg_tfidf_proba = logreg.predict_proba(tfidf_test)[:,1]\n",
    "precision_recall(y_test, pred_logreg_tfidf)\n",
    "\n",
    "cm4 = metrics.confusion_matrix(y_test, pred_logreg_tfidf, labels=[0,1])\n",
    "plot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Tf-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclass = SVC(kernel = 'linear', random_state = 0)\n",
    "scores = cross_val_score(svclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "svclass.fit(count_train, y_train)\n",
    "pred_sv_count = svclass.predict(count_test)\n",
    "precision_recall(y_test, pred_sv_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_sv_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a LSVM with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclass = SVC(kernel = 'linear', random_state = 0)\n",
    "scores = cross_val_score(svclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "svclass.fit(tfidf_train, y_train)\n",
    "pred_sv_count = svclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_sv_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_sv_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a LSVM with TFIDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclass = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(dtclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "dtclass.fit(count_train, y_train)\n",
    "pred_dt_count = dtclass.predict(count_test)\n",
    "precision_recall(y_test, pred_dt_count)\n",
    "\n",
    "cm4 = metrics.confusion_matrix(y_test, pred_dt_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a DT with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclass = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(dtclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "dtclass.fit(tfidf_train, y_train)\n",
    "pred_dt_count = dtclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_dt_count)\n",
    "\n",
    "cm5 = metrics.confusion_matrix(y_test, pred_dt_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a DT with TFIDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclass = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(rfclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "rfclass.fit(count_train, y_train)\n",
    "pred_rf_count = rfclass.predict(count_test)\n",
    "precision_recall(y_test, pred_rf_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_rf_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a RF with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclass = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "scores = cross_val_score(rfclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "rfclass.fit(tfidf_train, y_train)\n",
    "pred_rf_count = rfclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_rf_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_rf_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a RF with TFIDF Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "scores = cross_val_score(knnclass, count_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "knnclass.fit(count_train, y_train)\n",
    "pred_knn_count = knnclass.predict(count_test)\n",
    "precision_recall(y_test, pred_knn_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_knn_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a KNN with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knnclass = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "scores = cross_val_score(knnclass, tfidf_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "knnclass.fit(tfidf_train, y_train)\n",
    "pred_knn_count = knnclass.predict(tfidf_test)\n",
    "precision_recall(y_test, pred_knn_count)\n",
    "\n",
    "cm6 = metrics.confusion_matrix(y_test, pred_knn_count, labels=[0,1])\n",
    "plot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a KNN with Count Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
